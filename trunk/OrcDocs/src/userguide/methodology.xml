<chapter id="chapter.methodology" xmlns:xlink="http://www.w3.org/1999/xlink"><title>Programming Methodology</title>

<para>
In <link linkend="chapter.language">Chapter 1</link>, we described the syntax and semantics of the Orc language. 
Now, we turn our attention to how the language is used in practice, with guidelines on style and programming 
methodology, including a number of common concurrency patterns.
</para>

<section id="style.conventions"><title>Syntactic and Stylistic Conventions</title>

<para>
In this section we suggest some syntactic conventions for writing Orc programs. None of these 
conventions are required by the parser; newlines are used only to disambiguate certain corner
cases in parsing, and other whitespace is ignored. However, following programming convention 
helps to improve the readability of programs, so that the programmer's intent is more readily apparent.
</para>

<!--
<section><title>Identifiers</title>

By convention, identifiers bound to sites should begin with a capital letter (e.g. <code>Rwait</code>,
<code>Google</code>). Similarly, identifiers bound to functions which are strict and publish at 
most one value should also begin with a capital letter. Identifiers bound to functions which are not
strict, or may publish multiple values, should begin with a lowercase letter. Variable names
are typically lowercase but may be made uppercase if it seems stylistically appropriate.

</section>
 -->
 
<section><title>Parallel combinator</title> 
 
<para>
When the combined expressions are small, write them all on one line.

<programlisting>
<emphasis role="bold">F</emphasis> | <emphasis role="bold">G</emphasis> | <emphasis role="bold">H</emphasis>
</programlisting>

Note that we do not need parentheses here, since <code>|</code> is fully associative and commutative.
</para>

<para>
When the combined expressions are large enough to take up a full line, write one expression
per line, with each subsequent expression aligned with the first and preceded by <code>|</code>. 
Indent the first expression to improve readability.

<programlisting>
  <emphasis role="bold">long expression</emphasis> 
| <emphasis role="bold">long expression</emphasis>
| <emphasis role="bold">long expression</emphasis>
</programlisting>
 
</para>

<para>
A sequence of parallel expressions often form the left hand side of a sequential combinator. 
Since the sequential combinator has higher precedence, use parentheses to group the
combined parallel expressions together. 


<programlisting>
( <emphasis role="bold">expression</emphasis> 
| <emphasis role="bold">expression</emphasis>
)<![CDATA[ >x> ]]>
<emphasis role="bold">another expression</emphasis>
</programlisting>
</para>

</section>

<section><title>Sequential combinator</title>

<para>
When the combined expressions are small, write a cascade of sequential combinators
all on the same line.
</para> 

<programlisting>
<emphasis role="bold">F</emphasis><![CDATA[ >x> ]]><emphasis role="bold">G</emphasis><![CDATA[ >y> ]]><emphasis role="bold">H</emphasis>
</programlisting>

<para>
Remember that sequential is right associative; in this example, <code>x</code> is bound in both G and H, and <code>y</code> is
bound in H.
</para>

<para>
When the combined expressions are large enough to take up a full line, write one expression
per line; each line ends with the combinator which binds the publications
produced by that line.

<programlisting>
<emphasis role="bold">long expression</emphasis> <![CDATA[ >x> ]]> 
<emphasis role="bold">long expression</emphasis> <![CDATA[ >y> ]]>
<emphasis role="bold">long expression</emphasis>
</programlisting>
 
</para>

<para>
For very long-running expressions, or expressions that span multiple lines, write
the combinators on separate lines, indented, between each expression. 

<programlisting>
<emphasis role="bold">very long expression</emphasis> 
 <![CDATA[ >x> ]]> 
<emphasis role="bold">very long expression</emphasis> 
 <![CDATA[ >y> ]]>
<emphasis role="bold">very long expression</emphasis>
</programlisting>
 
</para>

</section>

<section id="style.pruning"><title>Pruning combinator</title>

<para>
When the combined expressions are small, write them on the same line:

<programlisting>
<emphasis role="bold">F</emphasis><![CDATA[ <x< ]]><emphasis role="bold">G</emphasis>
</programlisting>

When multiple pruning combinators are used to bind multiple variables
(especially when the scoped expression is long), start each line with a 
combinator, aligned and indented, and continue with the expression.

<programlisting>
<emphasis role="bold">long expression</emphasis> 
 <![CDATA[ <x< ]]><emphasis role="bold">G</emphasis>
 <![CDATA[ <y< ]]><emphasis role="bold">H</emphasis>
</programlisting>

</para>

<para>
The pruning combinator is not often written in its explicit form
in Orc programs. Instead, the <code>val</code> declaration is often more
convenient, since it is semantically equivalent and mentions the variable
<code>x</code> before its use in scope, rather than after.

<programlisting>
val x = <emphasis role="bold">G</emphasis>
val y = <emphasis role="bold">H</emphasis>
<emphasis role="bold">long expression</emphasis> 
</programlisting>

</para>

<para>
Additionally, when the variable is used in only one place, and the
expression is small, it is often easier to use a nested expression.
For example,

<programlisting>
val x = <emphasis role="bold">G</emphasis>
val y = <emphasis role="bold">H</emphasis>
M(x,y)
</programlisting>

is equivalent to

<programlisting>
M(<emphasis role="bold">G</emphasis>,<emphasis role="bold">H</emphasis>)
</programlisting>

</para>

<para>
Sometimes, we use the pruning combinator simply for its capability to terminate
expressions and get a single publication; binding a variable is irrelevant. This
is a special case of nested expressions. We use the identity site <code>let</code>
to put the expression in the context of a function call.
</para>

<para>
For example,

<programlisting>
x<![CDATA[ <x< ]]><emphasis role="bold">F</emphasis> | <emphasis role="bold">G</emphasis> | <emphasis role="bold">H</emphasis>
</programlisting>

is equivalent to

<programlisting>
let(<emphasis role="bold">F</emphasis> | <emphasis role="bold">G</emphasis> | <emphasis role="bold">H</emphasis>)
</programlisting>
</para>

<para>
The translation uses a pruning combinator, but we don't need to write the combinator, 
name an irrelevant variable, or worry about precedence (since the expression is enclosed
in parentheses as part of the call).
</para>

</section>

<section><title>Declarations</title>

<!--
<para>
Declarations should always end with a newline. 

<programlisting>
def add(x,y) = x + y
val z = 7
add(z,z)
</programlisting>

While the parser does not require a newline to end a declaration, it uses the 
newline to disambiguate certain corner cases in parsing, such as function application.
</para>
-->
	
<para>
When the body of a declaration spans multiple lines, start the body on a new line
after the <code>=</code> symbol, and indent the entire body.

<programlisting>
def f(x,y) =
    <emphasis role="bold">declaration</emphasis>
    <emphasis role="bold">declaration</emphasis>
    <emphasis role="bold">body expression</emphasis>
</programlisting>

</para>

<para>
Apply this style recursively; if a def appears within a def, indent its contents even further.

<programlisting>
def f(x,y) =
    <emphasis role="bold">declaration</emphasis>
    def helper(z) =
    	<emphasis role="bold">declaration in helper</emphasis>
    	<emphasis role="bold">declaration in helper</emphasis>
    	<emphasis role="bold">body of helper</emphasis>
    <emphasis role="bold">declaration</emphasis>
    <emphasis role="bold">body expression</emphasis>
</programlisting>


</para>

	<section><title>Ambiguous Declarations</title>

<para> The following situation could introduce syntactic ambiguity: the end
of a declaration (def or val) is followed by an expression that starts with a
non-alphanumeric symbol. Consider these example programs:
</para>

<para>
<programlisting><![CDATA[
def f() =       -- example 1
  def g() = h
  (x,y)
]]></programlisting>
</para>
		
<para>
<programlisting><![CDATA[
def f() =       -- example 2
  val t = h
  (x,y)
]]></programlisting>
</para>
		
<para>
<programlisting><![CDATA[
def f() =       -- example 3
  val t = u
  -3
]]></programlisting>
</para>
		
<para>  <code>(x,y)</code> may be interpreted as the parameter list of <code>h</code>, and <code>-3</code> as
continuation of <code>u</code>, or they may be regarded as completely
separate expressions (in this case, the goal expression of <code>def f</code>). To avoid this ambiguity, 
Orc imposes the following syntactic constraint:
</para>
		
<para><code>An expression that follows a declaration begins with an alphanumeric symbol</code></para>
	
<para>To circumvent this restriction, if (x,y) is an expression that follows a declaration, 
write it as <code>signal >> (x,y)</code>. Similarly, write <code>signal >> -3</code>, in case <code>-3</code> is
the goal expression in the above example.  Note that there are many solutions to this problem; for example
using <code>stop | (x,y)</code> is also valid.</para>

</section>
	
</section>

</section>



<section><title>Programming Idioms</title>

<para>
In this section we give Orc implementations of some standard idioms from
concurrent and functional programming. Despite the austerity of Orc's four
combinators, we are able to encode a variety of idioms straightforwardly.
</para>

<section xml:id="methodology.channels"><title>Channels</title>

<para>
Orc has no communication primitives like pi-calculus
channels<footnote><para>R. Milner. <citetitle>Communicating and Mobile Systems:
the &#x3C0;-Calculus</citetitle>. Cambridge University Press, May
1999.</para></footnote> or Erlang mailboxes<footnote><para>J. Armstrong, R.
Virding, C. Wikstr&#xF6;m, and M. Williams. <citetitle>Concurrent programming in
ERLANG (2nd ed.)</citetitle>. Prentice Hall International (UK) Ltd.,
Hertfordshire, UK, UK, 1996.</para></footnote>. Instead, it makes use of sites
to create channels of communication. 
</para>

<para>
The most frequently used of these sites is <code>Buffer</code>. When called, it
publishes a new asynchronous FIFO channel. That channel is a site with two
methods: <code>get</code> and <code>put</code>.  The call <code>c.get()</code>
takes the first value from channel <code>c</code> and publishes it, or blocks
waiting for a value if none is available. The call <code>c.put(v)</code> puts
<code>v</code> as the last item of <code>c</code> and publishes a signal.
</para>

<para>
A channel may be closed to indicate that it will not be sent any more values.
If the channel <code>c</code> is closed, <code>c.put(v)</code> always halts
(without modifying the state of the channel), and <code>c.get()</code> halts
once <code>c</code> becomes empty. The channel <code>c</code> may be closed by
calling either <code>c.close()</code>, which returns a signal once
<code>c</code> becomes empty, or <code>c.closenb()</code>, which returns a
signal immediately.
</para>

</section>

<section><title>Lists</title>

<para>
In the section on Cor, we were introduced to lists: how to construct them,
and how to match them against patterns. While it is certainly feasible to
write a specific function with an appropriate pattern match every time we
want to access a list, it is helpful to have a handful of common operations
on lists and reuse them.
</para>

<para>
One of the most common uses for a list is to send each of its elements through
a sequential combinator. Since the list itself is a single value, we want
to walk through the list and publish each one of its elements in parallel
as a value. The library function <code>each</code> does exactly that.
</para>

<para>
Suppose we want to send the message <code>invite</code> to each email
address in the list <code>inviteList</code>:

<programlisting><![CDATA[
each(inviteList) >address> Email(address, invite)
]]></programlisting>

</para>


<para>
Orc also adopts many of the list idioms of functional programming. The Orc library contains definitions
for most of the standard list functions, such as <code>map</code> and <code>fold</code>. Many of the
list functions internally take advantage of concurrency to make use of any available parallelism; for
example, the <code>map</code> function dispatches all of the mapped calls concurrently, and assembles
the result list once they all return using a fork-join.
</para>

</section>

<section id="methodology.streams"><title>Streams</title>

<para>
Sometimes a source of data is not explicitly represented by a list or other data structure. Instead,
it is made available through a site, which returns the values one at a time, each time it is called.
We call such a site a <firstterm>stream</firstterm>. It is analogous to an iterator in a language 
like Java. Functions can also be used as streams, though typically they will not be pure functions,
and should only return one value. A call to a stream may halt, to indicate that the end of the data
has been reached, and no more values will become available. It is often useful to detect the
end of a stream using the otherwise combinator. 
</para>

<para>
Streams are common enough in Orc programming that there is a library function to take all of the
available publications from a stream; it is called <code>repeat</code>, and it is analogous to
<code>each</code> for lists.
</para>

<programlisting><![CDATA[
def repeat(f) = f() >x> (x | repeat(f))
]]></programlisting>

<para>
The <code>repeat</code> function calls the site or function <code>f</code> with no arguments,
publishes its return value, and recurses to query for more values. <code>repeat</code> should
be used with sites or functions that block until a value is available. Notice that if any
call to <code>f</code> halts, then <code>repeat(f)</code> consequently halts. 
</para>

<para>
For example, it is very easy to treat a channel <code>c</code> as a stream, reading any 
values put on the channel as they become available:

<programlisting><![CDATA[
repeat(c.get)
]]></programlisting>

</para>

<!-- An example of a site that creates streams would be great; file I/O maybe? -->

</section>


<section xml:id="methodology.mutable"><title>Mutable References</title>

<para>
Variables in Orc are immutable. There is no assignment operator, and there is no way to
change the value of a bound variable. However, it is often useful to have mutable state
when writing certain algorithms. The Orc library contains two sites that offer simple 
mutable storage: <code>Ref</code> and <code>Cell</code>. It also provides the site <code>Array</code>
to create mutable arrays.
</para>

<para>
A word of caution: References, cells, and other mutable objects may be accessed concurrently
by many different parts of an Orc program, so race conditions may arise. 
</para> 


<section><title>Rewritable references</title>
<para>
The <code>Ref</code> site creates rewritable reference cells.

<programlisting language="orc-demo"><![CDATA[
val r = Ref(0)
println(r.read()) >>
r.write(2) >> 
println(r.read()) >>
stop
]]></programlisting>

</para>

<para>
These are very similar to ML's <code>ref</code> cells. <code>r.write(v)</code> stores
the value <code>v</code> in the reference <code>r</code>, overwriting any previous
value, and publishes a signal. <code>r.read()</code> publishes the current value stored
in <code>r</code>.
</para>

<para>
However, unlike in ML, a reference cell can be left initially empty by calling <code>Ref</code>
with no arguments. A read operation on an empty cell blocks until the cell is written.

<programlisting language="orc-demo"><![CDATA[
{- Create a cell, and wait 1 second before initializing it. -}
{- The read operation blocks until the write occurs. -}
val r = Ref()
r.read() | Rwait(1000) >> r.write(1) >> stop
]]></programlisting>

</para>

</section>

<section><title>Write-once references</title>

<para>
The Orc library also offers write-once reference cells, using the <code>Cell</code> site.
A write-once cell has no initial value. Read operations block until the cell has been
written. A write operation succeeds only if the cell is empty; subsequent write operations
simply halt.

<programlisting language="orc-demo"><![CDATA[
{- Create a cell, try to write to it twice, and read it -}
{- The read will block until a write occurs
   and only one write will succeed. -}
val r = Cell()
  Rwait(1000) >> r.write(2) >> println("Wrote 2") >> stop
| Rwait(1000) >> r.write(3) >> println("Wrote 3") >> stop
| r.read()
]]></programlisting>

Write-once cells are very useful for concurrent programming, and they are often safer
than rewritable reference cells, since the value cannot be changed once it has been
written. The use of write-once cells for concurrent programming is not a new idea;
they have been studied extensively in the context of the 
<link xlink:href="http://en.wikipedia.org/wiki/Oz_programming_language">Oz programming language</link>.
</para>

</section>


<section><title>Reference syntax</title>

<para>Orc provides syntactic sugar for reading and writing mutable storage:</para>

<itemizedlist>
<listitem><code>x?</code> is equivalent to <code>x.read()</code>. This operator
is of equal precedence with the dot operator and function application, so
you can write things like <code>x.y?.v?</code>. This operator is very similar
to the C languages's <code>*</code> operator, but is postfix instead of prefix.
	</listitem>
<listitem><code>x := y</code> is equivalent to <code>x.write(y)</code>.
This operator has higher precedence than the concurrency combinators and if/then/else,
but lower precedence than any of the other operators.</listitem>
</itemizedlist>

<para>Here is a previous example rewritten using this syntactic sugar:</para>

<programlisting language="orc-demo"><![CDATA[
{- Create a cell, try to write to it twice, and read it -}
{- The read will block until a write occurs
   and only one write will succeed. -}
val r = Cell()
  Rwait(1000) >> r := 2 >> println("Wrote 2") >> stop
| Rwait(1000) >> r := 3 >> println("Wrote 3") >> stop
| r?
]]></programlisting>

</section>

<section><title>Arrays</title>

<para>
While lists are a very useful data structure, they are not mutable, and they are not indexed. However, 
these properties are often needed in practice, so the Orc standard library provides a function 
<code>Array</code> to create mutable arrays. 
</para>

<para>
<code>Array(n)</code> creates an array of size <code>n</code> whose elements are all initially <code>null</code>. 
The array is used like a function; the call <code>A(i)</code> returns the <code>i</code>th element of the array 
<code>A</code>, which is then treated as a reference, just like the references created by <code>Ref</code>. A call 
with an out-of-bounds index halts, possibly reporting an error. 
</para>

<para>

The following program creates an array of size 10, and initializes each index i with the
ith power of 2. It then reads the array values at indices 3, 6, and 10. The read at index 10
halts because it is out of bounds (arrays are indexed from 0).

<programlisting language="orc-demo"><![CDATA[
val a = Array(10)
def initialize(i) = 
  if (i < 10) 
    then a(i) := 2 ** i  >>  initialize(i+1)
    else signal
initialize(0) >> (a(3)? | a(6)? | a(10)?)
]]>
</programlisting>

</para>

<para>

The standard library also provides a helper function <code>fillArray</code> which makes array initialization
easier. <code>fillArray(a, f)</code> initializes array <code>a</code> using function <code>f</code> by setting
element <code>a(i)</code> to the first value published by <code>f(i)</code>. When the array is fully
initialized, <code>fillArray</code> returns the array <code>a</code> that was passed (which makes it easier to
simultaneously create and initialize an array). Here are a few examples:

<programlisting language="orc-demo">
{- Create an array of 10 elements; element i is the ith power of 2 -}
fillArray(Array(10), lambda(i) = 2 ** i)
</programlisting>

<programlisting language="orc-demo">
{- Create an array of 5 elements; each element is a newly created buffer -}
fillArray(Array(5), lambda(_) = Buffer())
</programlisting>

<programlisting language="orc-demo">
{- Create an array of 2 channels -}
val A = fillArray(Array(2), lambda(_) = Buffer())

{- 
   Send true on channel 0,
   listen for a value on channel 0 and forward it to channel 1, 
   and listen for a value on channel 1 and publish it. 
-}
  A(0)?.put(true) >> stop
| A(0)?.get() >x> A(1)?.put(x) >> stop
| A(1)?.get()
</programlisting>
</para>


<para>
Since arrays are accessed by index, there is a library function specifically
designed to make programming with indices easier. The function <code>upto(n)</code> 
publishes all of the numbers from <code>0</code> to
<code>n-1</code> simultaneously; thus, it is very easy to access all of the elements of
an array simultaneously. Suppose we have an array <code>A</code> of <code>n</code> email 
addresses and would like to send the message <code>m</code> to each one.

<programlisting><![CDATA[
upto(n) >i> A(i)? >address> Email(address, m)
]]></programlisting>

</para>

</section>

</section>

<section><title>Loops</title>

<para>
Orc does not have any explicit looping constructs. Most of the time, where a loop
might be used in other languages, Orc programs use one of two strategies: 
</para>

<orderedlist>

<listitem>When the iterations of the loops can occur in parallel, write an expression
that expands the data into a sequence of publications, and
use a sequential operator to do something for each publication. This is the strategy
that uses functions like <code>each</code>, <code>repeat</code>, and <code>upto</code>.
</listitem>
<listitem>When the iterations of the loops must occur in sequence, write a tail
recursive function that iterates over the data. Any loop can be rewritten as a 
tail recursion. Typically the data of interest is in a list, so one of the standard
list functions, such as <code>foldl</code>, applies. The library also defines a
function <code>while</code>, which handles many of the common use cases of
while loops.
</listitem>
</orderedlist>

</section>

<section><title>Parallel Matching</title>

<para>
Matching a value against multiple patterns, as we have seen it so far, is a linear
process, and requires a <code>def</code> whose clauses have patterns in their
argument lists. Such a match is linear; each pattern is tried in order until
one succeeds.
</para>

<para>
What if we want to match a value against multiple patterns in parallel, executing
every clause that succeeds? Fortunately, this is very easy to do in Orc. Suppose
we have an expression F which publishes pairs of integers, and we want to publish
a signal for each 3 that occurs. 
</para>

<para>
We could write:

<programlisting>
<emphasis role="bold">F</emphasis><![CDATA[ >(x,y)>
  ( if(x=3) >> signal
  | if(y=3) >> signal ) 
]]>
</programlisting>

But there is a more general alternative:

<programlisting>
<emphasis role="bold">F</emphasis><![CDATA[ >x>
  ( x >(3,_)> signal
  | x >(_,3)> signal ) 
]]>
</programlisting>

The interesting case is the pair <code>(3,3)</code>, which is counted twice
because both patterns match it in parallel.
</para>

<para>
This parallel matching technique is sometimes used as an alternative to pattern matching using function
clauses, but only when the patterns are mutually exclusive.
</para>

<para>

For example,

<programlisting  language="orc-demo">
def helper([]) = 0
def helper([_]) = 1
def helper(_:_:_) = 2
helper([4,6])
</programlisting>

is equivalent to

<programlisting  language="orc-demo"><![CDATA[
[4,6] >x>
  x >[]> 0
| x >[_]> 1
| x >_:_:_> 2
]]></programlisting>

whereas

<programlisting  language="orc-demo">
def helper([]) = 0
def helper([_]) = 1
def helper(_) = 2
helper([5])
</programlisting>

is <emphasis>not</emphasis> equivalent to

<programlisting language="orc-demo"><![CDATA[
[5] >x>
  x >[]> 0
| x >[_]> 1
| x >_> 2
]]></programlisting>

because the clauses are not mutually exclusive. Function clauses must attempt to match in linear order, whereas
this expression matches all of the patterns in parallel. Here, it will match <code>[5]</code> two different ways,
publishing both <code>1</code> and <code>2</code>.
</para>

</section>

<section xml:id="methodology.forkjoin"><title>Fork-join</title>

<para>
One of the most common concurrent idioms is a <firstterm>fork-join</firstterm>: run two processes concurrently,
and wait for a result from each one. This is very easy to express in Orc. Whenever we write a <code>val</code>
declaration, the process computing that value runs in parallel with the rest of the program. So if we write
two <code>val</code> declarations, and then form a tuple of their results, this performs a fork-join.
</para>

<para>
<programlisting>
val x = <emphasis role="bold">F</emphasis>
val y = <emphasis role="bold">G</emphasis>
   signal >> (x,y)
</programlisting>
</para>

<para>
Fork-joins are a fundamental part of all Orc programs, since they are created by all nested expression
translations. In fact, the fork-join we wrote above could be expressed even more simply as just:
</para>

<para>
<programlisting>
(<emphasis role="bold">F</emphasis>,<emphasis role="bold">G</emphasis>)
</programlisting>
</para>


<section><title>Example: Machine initialization</title>

<para>
In Orc programs, we often use fork-join and recursion together to dispatch many tasks in parallel and wait
for all of them to complete. Suppose that given a machine <code>m</code>, calling <code>m.init()</code> 
initializes <code>m</code> and then publishes a signal when initialization is complete. The function 
<code>initAll</code> initializes a list of machines.
</para>

<programlisting><![CDATA[
def initAll([]) = signal
def initAll(m:ms) = ( m.init() , initAll(ms) ) >> signal
]]></programlisting>

<para>
For each machine, we fork-join the initialization of that machine (<code>m.init()</code>) with the initialization
of the remaining machines (<code>initAll(ms)</code>). Thus, all of the initializations proceed in parallel, and
the function returns a signal only when every machine in the list has completed its initialization. 
</para>

<para>
Note that if some machine fails to initialize, and does not return a signal, then the initialization procedure
will never complete. 
</para> 

</section>

<section id="example.auction"><title>Example: Simple parallel auction</title>

<para>
We can also use a recursive fork-join to obtain a value, rather than just signaling completion. Suppose we
have a list of bidders in a sealed-bid, single-round auction. Calling <code>b.ask()</code> requests a bid
from the bidder <code>b</code>. We want to ask for one bid from each bidder, and then return the highest
bid. The function <code>auction</code> performs such an auction for a list of bidders (<code>max</code> 
finds the maximum of its arguments):
</para>

<programlisting><![CDATA[
def auction([]) = 0
def auction(b:bs) = max(b.ask(), auction(bs))
]]></programlisting>

</section>

<para>
Note that all bidders are called simultaneously. Also note that if some bidder fails 
to return a bid, then the auction will never complete.  Later we will see
a <link linkend="example.auction-with-timeout">different solution</link> that addresses the issue of non-termination.
</para>

<section><title>Example: Barrier synchronization</title>

<para>
Consider an expression of the following form, where F and G are expressions and M and N are sites:

<programlisting>
M() <![CDATA[ >x> ]]> <emphasis role="bold">F</emphasis> | N() <![CDATA[ >y> ]]> <emphasis role="bold">G</emphasis>
</programlisting>

</para>

<para>
Suppose we would like to <emphasis>synchronize</emphasis> F and G, so that both start
executing at the same time, after both <code>M()</code> and <code>N()</code> respond.  This is easily done
using the fork-join idiom. In the following, we assume that <code>x</code> does not occur
free in G, nor <code>y</code> in F.

<programlisting>
( M() , N() ) <![CDATA[ >(x,y)> ]]> ( <emphasis role="bold">F</emphasis> | <emphasis role="bold">G</emphasis> )
</programlisting>

</para>

</section>

</section>

<section><title>Sequential Fork-Join</title>

<para>
Previous sections illustrate how Orc can use the fork-join idiom to process a
fixed set of expressions or a list of values.  Suppose that instead we wish to
process all the publications of an expression F, and once this processing is
complete, execute some expression G.  For example, F publishes the contents
of a text file, one line at a time, and we wish to print each line to the
console using the site <code>println</code>, then publish a signal after all lines
have been printed.
</para>

<para>
Sequential composition alone is not sufficient, because we have no way to
detect when all of the lines have been processed.  A recursive fork-join
solution would require that the lines be stored in a traversable data structure
like a list, rather than streamed as publications from F.  A better solution
uses the <code>;</code> combinator to detect when processing is complete:
</para>

<programlisting>
<emphasis role="bold">F</emphasis> >x> println(x) >> stop ; signal
</programlisting>

<para>
Since <code>;</code> only evaluates its right side if the left side does not publish,
we suppress the publications on the left side using <code>stop</code>. Here, we
assume that we can detect when F halts. If, for example,
F is publishing the lines of the file as it receives them over a socket,
and the sending party never closes the socket, then F never halts and no
signal is published.
</para>
</section>

<section><title>Priority Poll</title>

<para>
The otherwise combinator is also useful for trying alternatives in sequence. Consider an expression of
the form <code>F<subscript>0</subscript> ; F<subscript>1</subscript> ; F<subscript>2</subscript> ; ...</code>. If F<subscript>i</subscript> does not publish 
and halts, then F<subscript>i+1</subscript> is executed. We can think of the F<subscript>i</subscript>'s as a series of 
alternatives that are explored until a publication occurs.
</para>

<para>
Suppose that we would like to poll a list of buffers for available data.  The
list of buffers is ordered by priority. The first buffer in the list has the
highest priority, so it is polled first.  If it has no data, then the
next buffer is polled, and so on.
</para>

<para>
Here is a function which polls a prioritized list of buffers in this way. It
publishes the first item that it finds, removing it from the originating
buffer. If all buffers are empty, the function halts.  We use the <code>getnb</code> ("get non-blocking") method of the buffer, which retrieves the first
available item if there is one, and halts otherwise.
</para>

<programlisting>
def priorityPoll([]) = stop
def priorityPoll(b:bs) = b.getnb() ; priorityPoll(bs)
</programlisting>
</section>

<section><title>Parallel Or</title>

<para>
``Parallel or'' is a classic idiom of parallel programming.  The ``parallel or'' operation executes two
expressions F and G in parallel, each of which may publish a single boolean,
and returns the disjunction of their publications as soon as possible. 
If one of the expressions publishes <code>true</code>, then the disjunction is <code>true</code>, 
so it is not necessary to wait for the other expression to publish a value. 
This holds even if one of the expressions is silent.
</para>

<para>
The ``parallel or'' of expressions F and G may be expressed in Orc as
follows:
</para>

<programlisting>
let(
    val a = <emphasis role="bold">F</emphasis>
    val b = <emphasis role="bold">G</emphasis>
      signal >> (a || b)
       | if(a)<![CDATA[ >> ]]>true 
       | if(b)<![CDATA[ >> ]]>true 
)
</programlisting>

<para>
The expression <code>(a || b)</code> waits for both <code>a</code> and <code>b</code> to become
available and then publishes their disjunction.  However if either <code>a</code> or
<code>b</code> is true we can publish <code>true</code> immediately regardless of whether the
other variable is available.  Therefore we run <code>if(a) >> true</code> and <code>if(b) >> true</code>
in parallel to wait for either variable to become <code>true</code> and immediately
publish the result <code>true</code>.  Since more than one of these expressions may
publish <code>true</code>, the surrounding <code>let(...)</code> is necessary to select and
publish only the first result.
</para>

</section>


<section><title>Timeout</title>

<para>
<firstterm>Timeout</firstterm>, the ability to execute an expression for at most a specified
amount of time, is an essential ingredient of fault-tolerant and distributed
programming.  Orc accomplishes timeout using pruning and the <code>Rwait</code> site.
The following program runs F for at most one second, publishing its result if
available and the value <code>0</code> otherwise.
</para>

<programlisting>
let( <emphasis role="bold">F</emphasis> | Rwait(1000)<![CDATA[ >> ]]>0 )
</programlisting>


<section id="example.auction-with-timeout"><title>Auction with timeout</title>

<para>
In the <link linkend="example.auction">auction example</link> given previously, the auction may never complete if 
one of the bidders does not respond. We can add a timeout so that a bidder has at most 8 seconds to provide a bid:
</para>

<programlisting><![CDATA[
def auction([]) = 0
def auction(b:bs) = 
  val bid = b.ask() | Rwait(8000) >> 0
  max(bid, auction(bs))
]]></programlisting>

<para>
This version of the auction is guaranteed to complete within 8 seconds.
</para>

</section>


<section><title>Detecting timeout</title>

<para>
Sometimes, rather than just yielding a default value, we would like to
determine whether an expression has timed out, and if so, perform some other
computation.  To detect the timeout, we pair the result of the original
expression with <code>true</code> and the result of the timer with <code>false</code>.
Thus, if the expression does time out, then we can distinguish that case
using the boolean value.
</para>

<para>
Here, we run expression F with a time limit <code>t</code>. If it publishes
within the time limit, we bind its result to <code>r</code> and execute G.
Otherwise, we execute H.

<programlisting>
val (r, b) = (<emphasis role="bold">F</emphasis>, true) | (Rwait(t), false)
if b then <emphasis role="bold">G</emphasis> else <emphasis role="bold">H</emphasis>
</programlisting>

Instead of using a boolean and conditional, we could use pattern matching:

<programlisting><![CDATA[
val s = Some(]]><emphasis role="bold">F</emphasis><![CDATA[) | Rwait(t) >> None()
  s >Some(r)> ]]><emphasis role="bold">G</emphasis><![CDATA[
| s >None()>  ]]><emphasis role="bold">H</emphasis>
</programlisting>

</para>

<para>

It is even possible to encapsulate timeout as a function.

<programlisting><![CDATA[
def timeout(x, t) = let(Some(x) | Rwait(t) >> None())
]]></programlisting>

<code><![CDATA[timeout(]]><emphasis role="bold">F</emphasis><![CDATA[, t)]]></code> waits 
<code>t</code> milliseconds for F to publish a value. If F publishes <code>v</code> within
the time limit, <code>timeout</code> returns <code>Some(v)</code>. Otherwise, it returns
<code>None()</code> when the time limit is reached.

</para>

<section><title>Timeout streams</title>

<para>
We can also apply timeout to <link linkend="methodology.streams">streams</link>. Let's
define a modified version of the <code>repeat</code> function as follows:

<programlisting><![CDATA[
def repeatWithTimeout(f, t) = 
  timeout(f(), t) 
    >Some(x)> 
  (x | repeatWithTimeout(f, t))

]]></programlisting>
</para>

<para>
We call <code>f()</code> as before, but apply a timeout of <code>t</code> to the call.
If a value becomes available from <code>f</code> before the timeout, then the call to
<code>timeout</code> publishes <code>Some(x)</code>, which we match, and then publish
<code>x</code> and recursively wait for further values from the stream.
</para>

<para>
However, if no value is available from <code>f</code> within the timeout, the call 
to <code>timeout</code> publishes <code>None()</code>. Since <code>None()</code> does 
not match the pattern, the entire expression halts, indicating that the end of the
stream has been reached.
</para>

<para>
It is also possible to achieve this behavior with the existing <code>repeat</code> function,
simply by changing the function passed to <code>repeat</code>:

<programlisting><![CDATA[
def f'() = timeout(f(), t) >Some(x)> x
repeat(f')
]]></programlisting>

</para>


</section>
 
</section>

</section>

<section><title>Priority</title>

<para>
We can use a timer to give a window of priority to one computation over
another.  In this example, we run expressions F and G concurrently.  For
one second, F has priority; F's result is published immediately,
but G's result is held until the time interval has elapsed.  If neither F nor
G publishes a result within one second, then the first result from either
is published.

<programlisting>
val x = <emphasis role="bold">F</emphasis>
val y = <emphasis role="bold">G</emphasis>
let( y | Rwait(1000) >> x )
</programlisting>

</para>

</section>


<section><title>Metronome</title>

<para>
A timer can be used to execute an expression repeatedly at regular
intervals, for example to poll a service.
Recall the definition of <code>metronome</code> from the previous chapter:

<programlisting><![CDATA[
def metronome(t) = signal | Rwait(t) >> metronome()
]]></programlisting>
</para>

<para>
The following example publishes "tick" once per second and "tock" once per
second after an initial half-second delay.  The publications alternate: "tick
tock tick tock ...". Note that this program is not defined recursively;
the recursion is entirely contained within <code>metronome</code>.
</para>

<para>
<programlisting language="orc-demo"><![CDATA[
  metronome(1000) >> "tick"
| Rwait(500) >> metronome(1000) >> "tock"
]]></programlisting>
</para>

</section>





<section><title>Routing</title>

<para>
The Orc combinators restrict the passing of values among their component
expressions. However, some programs will require greater
flexibility.  For example, <code>F &lt;x&lt; G</code> provides F with the first 
publication of G, but what if F needs the first n publications of G?  
In cases like this we use channels or other stateful sites to redirect or 
store publications.  We call this technique <firstterm>routing</firstterm>
because it involves routing values from one execution to another.
</para>

<section><title>Generalizing Termination</title>

<para>
The pruning combinator terminates an expression after it publishes its first
value. We have <link linkend="style.pruning">already seen</link> how to use 
pruning just for its termination capability, without binding a variable, using 
the <code>let</code> site. Now, we use routing to terminate an expression
under different conditions, not just when it publishes a value; it may
publish many values, or none, before being terminated.
</para>

<para>
Our implementation strategy is to route the publications of the expression
through a channel, so that we can put the expression inside a pruning combinator
and still see its publications without those publications terminating the
expression. 
</para>

<section><title>Enhanced Timeout</title>

<para>
As a simple demonstration of this concept, we construct a more powerful form 
of timeout: allow an expression to execute, publishing arbitrarily many values 
(not just one), until a time limit is reached.
</para>

<programlisting>
val c = Buffer()
repeat(c.get)<![CDATA[ << ]]>
    <emphasis role="bold">F</emphasis><![CDATA[ >x> c.put(x) >> stop 
  | Rwait(1000) >> c.closenb()]]></programlisting>

<para>
This program allows F to execute for one second and then terminates it. Each
value published by F is routed through channel <code>c</code> so that it does
not terminate F. After one second, <code>Rwait(1000)</code> responds,
triggering the call <code>c.closenb()</code>.  The call
<code>c.closenb()</code> closes <code>c</code> and publishes a signal,
terminating F.  The library function <code>repeat</code> is used to repeatedly
take and publish values from <code>c</code> until it is closed.
</para>

</section>


<section><title>Test Pruning</title>

<para>
We can also decide to terminate based on the values published. This expression
executes F until it publishes a negative number, and then terminates it:
</para>

<programlisting>
val c = Buffer()
repeat(c.get)<![CDATA[ << ]]>
  <emphasis role="bold">F</emphasis><![CDATA[ >x> 
    (if x >= 0 
        then c.put(x) >> stop
        else c.closenb())]]>
</programlisting>

<para>
Each value published by F is tested. If it is non-negative, it is placed on
channel <code>c</code> (silently) and read by <code>repeat(c.get)</code>. 
If it is negative, the channel is closed, publishing a signal and causing
the termination of F.
</para>

</section>

<section><title>Interrupt</title>

<para>
We can use routing to interrupt an expression based on a signal from
elsewhere in the program.  We set up the expression like a timeout, but instead
of waiting for a timer, we wait for the semaphore <code>done</code> to be released. Any
call to <code>done.release</code> will terminate the expression (because it will
cause <code>done.acquire()</code> to publish), but otherwise F executes as normal and
may publish any number of values.
</para>

<programlisting><![CDATA[
val c = Buffer()
val done = Semaphore(0)
repeat(c.get) <<
    ]]><emphasis role="bold">F</emphasis><![CDATA[ >x> c.put(x) >> stop
  | done.acquire() >> c.closenb()]]></programlisting>

</section>

<section><title>Publication Limit</title>

<para>
We can limit an expression to <emphasis>n</emphasis> publications,
rather than just one. Here is an expression which executes F until
it publishes 5 values, and then terminates it.
</para>

<programlisting><![CDATA[
val c = Buffer()
val done = Semaphore(0)
def allow(0) = done.release() >> stop
def allow(n) = c.get() >x> (x | allow(n-1))
allow(5) << ]]>
    <emphasis role="bold">F</emphasis><![CDATA[ >x> c.put(x) >> stop 
  | done.acquire() >> c.closenb()
]]>
</programlisting>

<para>
We use the auxiliary function <code>allow</code> to get only the first 5
publications from the channel <code>c</code>.  When no more publications are allowed,
<code>allow</code> uses the interrupt idiom to halt F and close <code>c</code>.
</para>

</section>


</section>


<section><title>Non-Terminating Pruning</title>

<para>
We can use routing to create a modified version of the pruning combinator.
As in <code>F &lt;x&lt; G</code>, we'll run F and G in parallel and make the first
value published by G available to F.  However instead of terminating G after
it publishes a value, we will continue running it, ignoring its remaining
publications.
</para>

<programlisting><![CDATA[
val r = Cell()
signal >>
   (]]><emphasis role="bold">F</emphasis><![CDATA[ <x< c.read()) | (]]><emphasis role="bold">G</emphasis><![CDATA[ >x> c.write(x))
]]>
</programlisting>

</section>

<section><title>Publication-Agnostic Otherwise</title>

<para>
We can also use routing to create a modified version of the otherwise combinator. We'll
run F until it halts, and then run G, regardless of whether F published any values
or not.
</para>

<programlisting><![CDATA[
val c = Buffer()
repeat(c.get) | (]]><emphasis role="bold">F</emphasis><![CDATA[ >x> c.put(x) >> stop ; c.close() >> ]]><emphasis role="bold">G</emphasis>)  
</programlisting>

We use <code>c.close()</code> instead of the more common <code>c.closenb()</code>
to ensure that G does not execute until all the publications of F have been
routed. Recall that <code>c.close()</code> does not return until <code>c</code> is
empty.

</section>

</section>

<section><title>Interruption</title>

<para>
We can write a function <code>interruptible</code> that implements the interrupt idiom
to execute any function in an interruptible way.  <code>interruptible(g)</code>
calls the function <code>g</code>, which is assumed to take no arguments, and
silences its publications. It immediately publishes another function, which we
can call at any time to terminate the execution of <code>g</code>. For simplicity,
we assume that <code>g</code> itself publishes no values.
</para>

<para>
Here is a naive implementation that doesn't quite work:
</para>

<programlisting><![CDATA[
def interruptible(f) =
  val done = Semaphore(0)
  done.release
    << f() >> stop 
     | done.acquire() >> c.closenb()

{- wrong! -}
val stopper = interruptible(g)
...
]]>
</programlisting>

<para>
The function <code>interruptible</code> is correct, but the way it is used causes a strange error.
The function <code>g</code> executes, but is always immediately terminated! This happens because the
<code>val</code> declaration which binds <code>stopper</code> also kills all of the remaining
computation in <code>interruptible(g)</code>, including the execution of <code>g</code> itself.
</para>

<para>
The solution is to bind the variable differently:
</para>

<programlisting><![CDATA[
def interruptible(f) =
  val done = Semaphore(0)
  done.release
    << f() >> stop 
     | done.acquire() >> c.closenb()

interruptible(g) >stopper>
...
]]>
</programlisting>

<para>
This idiom, wherein a function publishes some value that can be used to monitor or control its 
execution, arises occasionally in Orc programming. When using this idiom, always remember to
avoid terminating that execution accidentally. Since Orc is a structured concurrent language,
every process is contained with some other process; kill the containing process, and the
contained processes die too.
</para>

</section>

<section><title>Lifting</title>

It is often useful to explicitly lift an execution, so that it is in some sense protected from
being terminated. We can do this by running a "lifter" process, to which we can send functions
that will be executed by the lifter and thus will not be terminated unless the lifter itself
is terminated.

Such a lifter is written by creating a channel, and running a loop which listens for functions to
be sent on the channel and executes those functions as they arrive. The lifter publishes only
the put method for the channel; the loop itself publishes no values, since the values published by the 
lifted functions are silenced.

Here, we write such a lifter, and then use it to protect a function call from a timeout.

<programlisting language="orc-demo"><![CDATA[
def lifter() =
  val c = Buffer()
  def loop() = c.get() >f> ( f() >> stop | loop() )
  c.put | loop()

def delayedPrint() = Rwait(1500) >> println("Delayed 1.5 seconds")

lifter() >lift>
(
println("Running...") 
  << Rwait(1000) | delayedPrint() | lift(delayedPrint)
)
]]>
</programlisting>

The timeout stops the execution of <code>delayedPrint()</code>, so it does not print a result.
However, the lifted execution of <code>delayedPrint</code> does succeed, since it is executing
within the loop of <code>lifter()</code>, unaffected by the timeout.

</section>

<section><title>Fold</title>

<para>
We consider various concurrent implementations of the classic "list fold"
function from functional programming:
</para>

<programlisting><![CDATA[
def fold(_, [x])  = x
def fold(f, x:xs) = f(x, fold(xs))]]></programlisting>

<para>
This is a seedless fold (sometimes called <code>fold1</code>) which requires that the
list be nonempty and uses its first element as a seed.  This implementation is
short-circuiting --- it may finish early if the reduction operator <code>f</code> does
not use its second argument --- but it is not concurrent; no two calls to <code>f</code>
can proceed in parallel.  However, if <code>f</code> is associative, we can overcome this restriction 
and implement fold concurrently. If <code>f</code> is also commutative, we can further increase concurrency.
</para>

<section><title>Associative Fold</title>

<para>
We first consider the case when the reduction operator is associative.  We
define <code>afold(f,xs)</code> where <code>f</code> is a binary associative function and
<code>xs</code> is a non-empty list.  The implementation iteratively reduces <code>xs</code>
to a single value.  Each step of the iteration applies the auxiliary function
<code>step</code>, which halves the size of <code>xs</code> by reducing disjoint pairs of
adjacent items. 
</para>

<programlisting><![CDATA[
def afold(_, [x]) = x
def afold(f, xs) =
  def step([]) = []
  def step([x]) = [x]
  def step(x:y:xs) = f(x,y):step(xs)
  afold(f, step(xs))]]>
</programlisting>

<para>
Notice that <code>f(x,y):step(xs)</code> is an implicit
fork-join. Thus, the call <code>f(x,y)</code>
executes in parallel with the recursive call <code>step(xs)</code>. 
As a result, all calls to <code>f</code> execute concurrently within
each iteration of <code>afold</code>.   
</para>
  
</section>

<section><title>Associative, Commutative Fold</title>

<para>
We can make the implementation even more concurrent when the fold operator 
is both associative and commutative. We define <code>cfold(f,xs)</code>, where 
<code>f</code> is a associative and commutative binary function and <code>xs</code> is a non-empty list. 
The implementation initially copies all list items into a buffer in arbitrary
order using the auxiliary function <code>xfer</code>, counting the total
number of items copied. The auxiliary function <code>combine</code> repeatedly 
pulls pairs of items from the buffer, reduces
them, and places the result back in the buffer. Each pair of items is reduced
in parallel as they become available. The last item in the buffer is the
result of the overall fold.
</para>

<programlisting><![CDATA[
def cfold(f, xs) =
  val c = Buffer()
  
  def xfer([])    = 0
  def xfer(x:xs)  = c.put(x) >> stop | xfer(xs)+1

  def combine(0) = stop
  def combine(1) =  c.get()
  def combine(m) =  c.get() >x> c.get() >y> 
                    ( c.put(f(x,y)) >> stop | combine(m-1))

  xfer(xs) >n> combine(n)]]>
</programlisting>

</section>
</section>

</section>


<section><title>Larger Examples</title>

In this section we show a few larger Orc programs to demonstrate programming techniques. 
There are many more such examples available at the Orc website, on the
<link xlink:href="http://orc.csres.utexas.edu/wiki/Wiki.jsp?page=WikiLab">community wiki</link>.


<section><title>Dining Philosophers</title>

<para>
The dining philosophers problem is a well known and intensely studied problem
in concurrent programming. Five philosophers sit around a circular table. Each
philosopher has two forks that she shares with her neighbors (giving five forks
in total).  Philosophers think until they become hungry.  A hungry philosopher
picks up both forks, one at a time, eats, puts down both forks, and then
resumes thinking.  Without further refinement, this scenario allows deadlock;
if all philosophers become hungry and pick up their left-hand forks
simultaneously, no philosopher will be able to pick up her right-hand fork to
eat.  Lehmann and Rabin's solution<footnote><para>D. J. Lehmann and M. O. Rabin. On the advantages of free choice: A symmetric
and fully distributed solution to the dining philosophers problem. In <emphasis>POPL</emphasis>, pages
133–138, 1981.</para></footnote>, which we implement,
requires that each philosopher pick up her forks in a random order.  If the
second fork is not immediately available, the philosopher must set down both
forks and try again.  While livelock is still possible if all philosophers
take forks in the same order, randomization makes this possibility vanishingly
unlikely.
</para>

<programlisting language="orc-demo"><![CDATA[
def shuffle(a,b) = if (random(2) = 1) then (a,b) else (b,a)

def take((a,b)) =    
  a.acquire() >> b.acquirenb() ;
  a.release() >> take(shuffle(a,b))
    
def drop(a,b) = (a.release(), b.release()) >> signal

def phil(n,a,b) =
  def thinking() = 
    println(n + " thinking") >> 
    if (random(10) < 9)
      then Rwait(random(1000))
      else stop
  def hungry() = take((a,b))
  def eating() = 
    println(n + " eating") >> 
    Rwait(random(1000)) >> 
    println(n + " done eating") >> 
    drop(a,b)
  thinking() >> hungry() >> eating() >> phil(n,a,b)

def philosophers(1,a,b) = phil(1,a,b)
def philosophers(n,a,b) =
  val c = Semaphore(1)
  philosophers(n-1,a,c) | phil(n,c,b)

val fork = Semaphore(1)
philosophers(5,fork,fork)]]></programlisting>

<para>
The <code>phil</code> function simulates a single philosopher.  It takes as arguments
two binary semaphores representing the philosopher's forks, and calls
the <code>thinking</code>, <code>hungry</code>, and <code>eating</code> functions in a continuous
loop. A <code>thinking</code> philosopher waits for a random amount of time, with a
10% chance of thinking forever. A <code>hungry</code> philosopher uses the <code>take</code>
function to acquire two forks. An <code>eating</code> philosopher waits for a random
time interval and then uses the <code>drop</code> function to relinquish ownership of
her forks.
</para>

<para>
Calling <code>take(a,b)</code> attempts to acquire a pair of forks <code>(a,b)</code> in two steps:
wait for fork <code>a</code> to become available, then immediately attempt to acquire fork <code>b</code>.
The call <code>b.acquirenb()</code> either acquires <code>b</code> and responds immediately, or halts if <code>b</code> is not available.
If <code>b</code> is acquired, signal success; otherwise, release <code>a</code>, and
then try again, randomly changing the order in which the forks are acquired
using the auxiliary function <code>shuffle</code>.
</para>

<para>
The function call <code>philosophers(n,a,b)</code> recursively creates a chain of <code>n</code>
philosophers, bounded by fork <code>a</code> on the left and <code>b</code> on the right. The
goal expression of the program calls <code>philosophers</code> to create a chain of
five philosophers bounded on the left and right by the same fork; hence, a
ring.
</para>

<para>
This Orc solution has several nice properties.  The overall structure of the
program is functional, with each behavior encapsulated in its own function,
making the program easy to understand and modify.  Mutable state is isolated to
the "fork" semaphores and associated <code>take</code> and <code>get</code> functions,
simplifying the implementation of the philosophers.  The program never
manipulates threads explicitly, but instead expresses relationships between
activities using Orc's combinators.
</para>

</section>

<section id="methodology.examples.hygenic"><title>Hygienic Dining Philosophers</title>

<para>
Here we implement a different solution to the Dining Philosophers problem,
described in "The Drinking Philosophers Problem", by K. M. Chandy and J. Misra.
Briefly, this algorithm efficiently and fairly solves the dining philosophers
problem for philosophers connected in an arbitrary graph (as opposed to a
simple ring).  The algorithm works by augmenting each fork with a clean/dirty
state.  Initially, all forks are dirty.  A philosopher is only obliged to
relinquish a fork to its neighbor if the fork is dirty. On receiving a fork,
the philosopher cleans it. On eating, the philosopher dirties all forks.  For
full details of the algorithm, consult the original paper.
</para>

<programlisting language="orc-demo"><![CDATA[
{-
Start a philosopher actor; never publishes.
Messages sent between philosophers include:
- ("fork", p): philosopher p relinquishes the fork
- ("request", p): philosopher p requests the fork
- ("rumble", p): sent by a philosopher to itself when it should
  become hungry

name: identify this process in status messages
mbox: our mailbox; the "address" of this philosopher is mbox.put
missing: set of neighboring philosophers holding our forks
-}
def philosopher(name, mbox, missing) =
  {- deferred requests for forks -}
  val deferred = Buffer()
  {- forks we hold which are clean -}
  val clean = Set()

  def sendFork(p) =
    {- remember that we no longer hold the fork -}
    missing.add(p) >>
    p(("fork", mbox.put))
 
  def requestFork(p) =
    p(("request", mbox.put))
  
  {- Start a timer which will tell us when we're hungry. -}
  def digesting() =
      println(name + " thinking") >>
      thinking()
    | Rwait(random(1000)) >>
      mbox.put(("rumble", mbox.put)) >>
      stop

  {- Wait to become hungry -}
  def thinking() =
    def on(("rumble", _)) =
      println(name + " hungry") >>
      map(requestFork, missing) >>
      hungry()
    def on(("request", p)) =
      sendFork(p) >> thinking()
    on(mbox.get())

  {- Eat once we receive all forks -}
  def hungry() =
    def on(("fork", p)) =
      missing.remove(p) >>
      clean.add(p) >>
      if missing.isEmpty()
      then println(name + " eating") >> eating()
      else hungry()
    def on(("request", p)) =
      if clean.contains(p)
      then deferred.put(p) >> hungry()
      else sendFork(p) >> requestFork(p) >> hungry()
    on(mbox.get())

  {- Dirty forks, process deferred requests, then digest -}
  def eating() =
    clean.clear() >>
    Rwait(random(1000)) >>
    map(sendFork, deferred.getAll()) >>
    digesting()

  {- All philosophers start out digesting -}
  digesting()

{-
Create an NxN 4-connected grid of philosophers.  Each philosopher
holds the fork for the connections below and to the right (so the
top left philosopher holds both its forks).
-}
def philosophers(n) =
  {- A set with 1 item -}
  def Set1(item) = Set() >s> s.add(item) >> s
  {- A set with 2 items -}
  def Set2(i1, i2) = Set() >s> s.add(i1) >> s.add(i2) >> s

  {- create an NxN matrix of mailboxes -}
  val cs = uncurry(Table(n, lambda (_) = Table(n, ignore(Buffer))))

  {- create the first row of philosophers -}
  philosopher((0,0), cs(0,0), Set())
  | for(1, n) >j>
    philosopher((0,j), cs(0,j), Set1(cs(0,j-1).put))

  {- create remaining rows -}
  | for(1, n) >i> (
      philosopher((i,0), cs(i,0), Set1(cs(i-1,0).put))
      | for(1, n) >j>
        philosopher((i,j), cs(i,j), Set2(cs(i-1,j).put, cs(i,j-1).put))
    )

{- Simulate a 3x3 grid of philosophers for 10 seconds -}
let(
  philosophers(3)
  | Rwait(10000)
) >> "HALTED"]]></programlisting>

<para>
Our implementation is based on the <link
xlink:href="http://en.wikipedia.org/wiki/Actor_model">actor model</link> of
concurrency.  An actor is a state machine which reacts to messages.  On
receiving a message, an actor can send asynchronous messages to other actors,
change its state, or create new actors.  Each actor is single-threaded and
processes messages sequentially, which makes some concurrent programs easier to
reason about and avoids explicit locking. <link
	xlink:href="http://www.erlang.org/">Erlang</link> is one popular
language based on the actor model.
</para>

<para>
Orc emulates the actor model very naturally.  In Orc, an actor is an Orc thread
of execution, together with a <code>Buffer</code> which serves as a mailbox.  To send a
message to an actor, you place it in the actor's mailbox, and to receive a
message, the actor gets the next item from the mailbox.  The internal states of
the actor are represented by functions: while an actor's thread of execution is
evaluating a function, it is considered to be in the corresponding state.
Because Orc implements <link
xlink:href="http://en.wikipedia.org/wiki/Tail_call">tail-call optimization</link>,
state transitions can be encoded as function calls without running out of stack
space.
</para>

<para>
In this program, a philosopher is implemented by an actor with three primary
states: <code>eating</code>, <code>thinking</code>, and <code>hungry</code>.
An additional transient state, <code>digesting</code>, is used to start a timer
which will trigger the state change from <code>thinking</code> to
<code>hungry</code>.  Each state is implemented by a function which reads a
message from the mailbox, selects the appropriate action using pattern
matching, performs the action, and finally transitions to the next state
(possibly the same as the current state) by calling the corresponding function.
</para>

<para>
Forks are never represented explicitly.  Instead each philosopher identifies a
fork with the "address" (sending end of a mailbox) of the neighbor who shares
the fork.  Every message sent includes the sender's address.  Therefore when a
philosopher receives a request for a fork, it knows who requested it and
therefore which fork to relinquish.  Likewise when a philosopher receives a
fork, it knows who sent it and therefore which fork was received.
</para>
</section>

<section><title>Readers-Writers</title>

<para>
Here we present an Orc solution to the <link
xlink:href="http://en.wikipedia.org/wiki/Readers-writers_problem">readers-writers
problem</link>.  Briefly, the readers-writers problem involves concurrent
access to a mutable resource.  Multiple readers can access the resource
concurrently, but writers must have exclusive access.  When readers and writers
conflict, different solutions may resolve the conflict in favor of one or the
other, or fairly.  In the following solution, when a writer tries to acquire
the lock, current readers are allowed to finish but new readers are postponed
until after the writer finishes.  Lock requests are granted in the order
received, guaranteeing fairness.  Normally, such a service would be provided to
Orc programs by a site, but it is educational to see how it can be implemented
directly in Orc.
</para>

<programlisting language="orc-demo"><![CDATA[
-- Queue of lock requests
val m = Buffer()
-- Count of active readers/writers
val c = Counter()

{-- Process requests in sequence --}
def process() =
  -- Grant read request
  def grant((false,s)) = c.inc() >> s.release()
  -- Grant write request
  def grant((true,s)) =
    c.onZero() >> c.inc() >> s.release() >> c.onZero()
  -- Goal expression of process()
  m.get() >r> grant(r) >> process()

{-- Acquire the lock: argument is "true" if writing --}
def acquire(write) =
  val s = Semaphore(0)
  m.put((write, s)) >> s.acquire()

{-- Release the lock --}
def release() = c.dec()

-------------------------------------------------

{-- These definitions are for testing only --}
def reader(start) = Rwait(start) >>
  acquire(false) >> println("START READ") >>
  Rwait(1000) >> println("END READ") >>
  release() >> stop
def writer(start) = Rwait(start) >>
  acquire(true) >> println("START WRITE") >>
  Rwait(1000) >> println("END WRITE") >>
  release() >> stop

let(
    process()  {- Output:     -}
  | reader(10) {- START READ  -}
  | reader(20) {- START READ  -}
               {- END READ    -}
               {- END READ    -}
  | writer(30) {- START WRITE -}
               {- END WRITE   -}
  | reader(40) {- START READ  -}
  | reader(50) {- START READ  -}
               {- END READ    -}
               {- END READ    -}
  -- halt after the last reader finishes
  | Rwait(60) >> acquire(true)
)]]></programlisting>

<para>
The lock receives requests over the channel <code>m</code> and processes them
sequentially with the function <code>grant</code>. Each request includes a
boolean flag which is true for write requests and false for read requests, and a
<code>Semaphore</code> which the requester blocks on.  The lock grants access
by releasing the semaphore, unblocking the requester.
</para>

<para>
The counter <code>c</code> tracks the number of readers or writers currently
holding the lock.  Whenever the lock is granted, <code>grant</code> increments
<code>c</code>, and when the lock is released, <code>c</code> is decremented.
To ensure that a writer has exclusive access, <code>grant</code> waits for the
<code>c</code> to become zero before granting the lock to the writer, and then
waits for <code>c</code> to become zero again before granting any more requests.
</para>
</section>

<section><title>Quicksort</title>

<para>
The original quicksort algorithm
<footnote><para>C. A. R. Hoare. Partition: Algorithm 63, Quicksort: Algorithm 64, and
Find: Algorithm 65. <emphasis>Communications of the ACM</emphasis>,
4(7):321–322, 1961.</para></footnote>
was designed for efficient execution on a uniprocessor.
Encoding it as a functional program typically ignores its efficient
rearrangement of the elements of an array.
Further, no known implementation highlights its concurrent aspects.
The following program attempts to overcome these two limitations.
The program is mostly functional in its structure, though it manipulates the
array elements in place.
We encode parts of the algorithm as concurrent activities where sequentiality
is unneeded.
</para>

<para>
The following listing gives the implementation of the <code>quicksort</code>
function which sorts the array <code>a</code> in place.
The auxiliary function <code>sort</code> sorts the subarray given by indices
<code>s</code> through <code>t</code> by calling <code>part</code> to partition
the subarray and then recursively sorting the partitions.
</para>

<programlisting><![CDATA[
def quicksort(a) =

  def swap(x, y) = a(x)? >z> a(x) := a(y)? >> a(y) := z

  def part(p, s, t) =
    def lr(i) = if i < t && a(i)? <= p then lr(i+1) else i
    def rl(i) = if a(i)? > p then rl(i-1) else i

    signal >>
      (lr(s), rl(t)) >(s', t')>
      ( if (s' + 1 < t') >> swap(s', t') >> part(p, s'+1, t'-1)
      | if (s' + 1 = t') >> swap(s', t') >> s'
      | if (s' + 1 > t') >> t'
      )

  def sort(s, t) =
     if s >= t then signal
     else part(a(s)?, s+1, t) >m>
          swap(m, s) >>
          (sort(s, m-1), sort(m+1, t)) >>
          signal

  sort(0, a.length()-1)]]></programlisting>

<para>
The function <code>part</code> partitions the subarray given by indices
<code>s</code> through <code>t</code> into two partitions, one containing values
less than or equal to <code>p</code> and the other containing values &gt; <code>p</code>.  The last index of the lower partition is returned.
The value at <code>a(s-1)</code> is assumed to be less than or equal to <code>p</code> --- this is satisfied
by choosing <code>p = a(s-1)?</code> initially.  To create the partitions, <code>part</code>
calls two auxiliary functions <code>lr</code> and <code>rl</code> concurrently.  These
functions scan from the left and right of the subarray respectively, looking
for out-of-place elements.  Once two such elements have been found, they are
swapped using the auxiliary function <code>swap</code>, and then the unscanned portion
of the subarray is partitioned further.  Partitioning is complete when the
entire subarray has been scanned.
</para>

<para>
This program uses the syntactic sugar <code>x?</code> for <code>x.read()</code>
and <code>x := y</code> for <code>x.write(y)</code>.  Also note that the expression
<code>a(i)</code> returns a reference to the element of array <code>a</code> at index
<code>i</code>, counting from 0.
</para>
</section>

<section><title>Meeting Scheduler</title>

<para>
Orc makes very few assumptions about the behaviors of services it uses. Therefore
it is straightforward to write programs which interact with human agents and
network services.  This makes Orc especially suitable for encoding
<firstterm>workflows</firstterm>, the coordination of multiple activities
involving multiple participants.  The following program illustrates a simple
workflow for scheduling a business meeting.  Given a list of people and a date
range, the program asks each person when they are available for a meeting.  It
then combines all the responses, selects a meeting time which is acceptable to
everyone, and notifies everyone of the selected time.
</para>

<programlisting><![CDATA[
include "net.inc"
val during = Interval(LocalDate(2009, 9, 10),
                      LocalDate(2009, 10, 17))
val invitees = ["john@example.com", "jane@example.com"]

def invite(invitee) =
  Form() >f>
  f.addPart(DateTimeRangesField("times",
    "When are you available for a meeting?", during, 9, 17)) >>
  f.addPart(Button("submit", "Submit")) >>
  SendForm(f) >receiver>
  SendMail(invitee, "Meeting Request", receiver.getURL()) >>
  receiver.get() >response>
  response.get("times")

def notify([]) =
  each(invitees) >invitee>
  SendMail(invitee, "Meeting Request Failed",
                    "No meeting time found.")
def notify(first:_) =
  each(invitees) >invitee>
  SendMail(invitee, "Meeting Request Succeeded",
                    first.getStart())

map(invite, invitees) >responses>
afold(lambda (a,b) = a.intersect(b), responses) >times>
notify(times)]]></programlisting>

<para>
This program begins with declarations of <code>during</code> (the date range for the
proposed meeting) and <code>invitees</code> (the list of people to invite represented
by email addresses).
</para>

<para>
The <code>invite</code> function obtains possible meeting times from a given invitee, as
follows.  First it uses library sites (<code>Form</code>, <code>DateTimeRangesField</code>,
<code>Button</code>, and <code>SendForm</code>) to construct a web form which may be used to
submit possible meeting times.  Then it emails the URL of this form to the
invitee and blocks waiting for a response.  When the invitee receives the
email, he or she will use a web browser to visit the URL, complete the form,
and submit it.  The corresponding execution of <code>invite</code> receives the
response in the variable <code>response</code> and extracts the chosen meeting times.
</para>

<para>
The <code>notify</code> function takes a list of possible meeting times, selects the
first meeting time in the list, and emails everyone with this time.  If the
list of possible meeting times is empty, it emails everyone indicating that no
meeting time was found.
</para>

<para>
The goal expression of the program uses the library function <code>map</code> to
apply <code>notify</code> to each invitee and collect the responses in a list. It
then uses the library function <code>afold</code> to intersect all of the responses.
The result is a set of meeting times which are acceptable to everyone. Finally,
<code>notify</code> is called to select one of these times and notify everyone of the result.
</para>

<para>
This program may be extended to add more sophisticated features, such as a
quorum (to select a meeting as soon as some subset of invitees responds) or
timeouts (to remind invitees if they don't respond in a timely manner).  These
modifications are local and do not affect the overall structure of the program.
For complete details, see <link xlink:href="http://orc.csres.utexas.edu/tryorc.shtml">examples on our website</link>.
</para>
</section>

<!--
Procedural implementation of graphs is terrible for readability. 
Also, introducing this example would require an extended discussion of logical time.

<section><title>Shortest Path</title>


<programlisting><![CDATA[
def path(source, sink, cell, succ) =
  val timer = MakeTimer()
  def run(n,p) =
    cell(n).write(p) >>
    succ(n) >(m,d)>
    timer(d) >>
    run(m,m:p)
  run(source, [source])
  ; reverse(cell(sink).read())

{- A small test graph -}
val source = 0
val sink = 3

val cell0 = Cell()
val cell1 = Cell()
val cell2 = Cell()
val cell3 = Cell()

def cell(0) = cell0
def cell(1) = cell1
def cell(2) = cell2
def cell(3) = cell3

def succ(0) = (1,2) | (2,6) | (3,9)
def succ(1) = (3,7)
def succ(2) = (3,2)
def succ(3) = stop

{-
OUTPUT:
[0, 2, 3]
-}
path(source, sink, cell, succ)
]]></programlisting>

</section>
 -->
 
<!-- 
<section><title>Spellchecker</title>
</section>
-->

<!-- 
<section><title>Meeting Scheduler</title>
</section>
 -->


</section>
  
</chapter>